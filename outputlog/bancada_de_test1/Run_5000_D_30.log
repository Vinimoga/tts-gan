Generator(
  (l1): Linear(in_features=100, out_features=300, bias=True)
  (blocks): Gen_TransformerEncoder(
    (0): Gen_TransformerEncoderBlock(
      (0): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
          (1): MultiHeadAttention(
            (keys): Linear(in_features=10, out_features=10, bias=True)
            (queries): Linear(in_features=10, out_features=10, bias=True)
            (values): Linear(in_features=10, out_features=10, bias=True)
            (att_drop): Dropout(p=0.5, inplace=False)
            (projection): Linear(in_features=10, out_features=10, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
      (1): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
          (1): FeedForwardBlock(
            (0): Linear(in_features=10, out_features=40, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.5, inplace=False)
            (3): Linear(in_features=40, out_features=10, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
    )
    (1): Gen_TransformerEncoderBlock(
      (0): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
          (1): MultiHeadAttention(
            (keys): Linear(in_features=10, out_features=10, bias=True)
            (queries): Linear(in_features=10, out_features=10, bias=True)
            (values): Linear(in_features=10, out_features=10, bias=True)
            (att_drop): Dropout(p=0.5, inplace=False)
            (projection): Linear(in_features=10, out_features=10, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
      (1): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
          (1): FeedForwardBlock(
            (0): Linear(in_features=10, out_features=40, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.5, inplace=False)
            (3): Linear(in_features=40, out_features=10, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
    )
    (2): Gen_TransformerEncoderBlock(
      (0): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
          (1): MultiHeadAttention(
            (keys): Linear(in_features=10, out_features=10, bias=True)
            (queries): Linear(in_features=10, out_features=10, bias=True)
            (values): Linear(in_features=10, out_features=10, bias=True)
            (att_drop): Dropout(p=0.5, inplace=False)
            (projection): Linear(in_features=10, out_features=10, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
      (1): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
          (1): FeedForwardBlock(
            (0): Linear(in_features=10, out_features=40, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.5, inplace=False)
            (3): Linear(in_features=40, out_features=10, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
  (deconv): Sequential(
    (0): Conv2d(10, 3, kernel_size=(1, 1), stride=(1, 1))
  )
)
Discriminator(
  (0): PatchEmbedding_Linear(
    (projection): Sequential(
      (0): Rearrange('b c (h s1) (w s2) -> b (h w) (s1 s2 c)', s1=1, s2=15)
      (1): Linear(in_features=45, out_features=50, bias=True)
    )
  )
  (1): Dis_TransformerEncoder(
    (0): Dis_TransformerEncoderBlock(
      (0): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          (1): MultiHeadAttention(
            (keys): Linear(in_features=50, out_features=50, bias=True)
            (queries): Linear(in_features=50, out_features=50, bias=True)
            (values): Linear(in_features=50, out_features=50, bias=True)
            (att_drop): Dropout(p=0.5, inplace=False)
            (projection): Linear(in_features=50, out_features=50, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
      (1): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          (1): FeedForwardBlock(
            (0): Linear(in_features=50, out_features=200, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.5, inplace=False)
            (3): Linear(in_features=200, out_features=50, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
    )
    (1): Dis_TransformerEncoderBlock(
      (0): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          (1): MultiHeadAttention(
            (keys): Linear(in_features=50, out_features=50, bias=True)
            (queries): Linear(in_features=50, out_features=50, bias=True)
            (values): Linear(in_features=50, out_features=50, bias=True)
            (att_drop): Dropout(p=0.5, inplace=False)
            (projection): Linear(in_features=50, out_features=50, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
      (1): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          (1): FeedForwardBlock(
            (0): Linear(in_features=50, out_features=200, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.5, inplace=False)
            (3): Linear(in_features=200, out_features=50, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
    )
    (2): Dis_TransformerEncoderBlock(
      (0): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          (1): MultiHeadAttention(
            (keys): Linear(in_features=50, out_features=50, bias=True)
            (queries): Linear(in_features=50, out_features=50, bias=True)
            (values): Linear(in_features=50, out_features=50, bias=True)
            (att_drop): Dropout(p=0.5, inplace=False)
            (projection): Linear(in_features=50, out_features=50, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
      (1): ResidualAdd(
        (fn): Sequential(
          (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          (1): FeedForwardBlock(
            (0): Linear(in_features=50, out_features=200, bias=True)
            (1): GELU(approximate='none')
            (2): Dropout(p=0.5, inplace=False)
            (3): Linear(in_features=200, out_features=50, bias=True)
          )
          (2): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
  (2): ClassificationHead(
    (clshead): Sequential(
      (0): Reduce('b n e -> b e', 'mean')
      (1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
      (2): Linear(in_features=50, out_features=1, bias=True)
    )
  )
)
DataParallel(
  (module): Discriminator(
    (0): PatchEmbedding_Linear(
      (projection): Sequential(
        (0): Rearrange('b c (h s1) (w s2) -> b (h w) (s1 s2 c)', s1=1, s2=15)
        (1): Linear(in_features=45, out_features=50, bias=True)
      )
    )
    (1): Dis_TransformerEncoder(
      (0): Dis_TransformerEncoderBlock(
        (0): ResidualAdd(
          (fn): Sequential(
            (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
            (1): MultiHeadAttention(
              (keys): Linear(in_features=50, out_features=50, bias=True)
              (queries): Linear(in_features=50, out_features=50, bias=True)
              (values): Linear(in_features=50, out_features=50, bias=True)
              (att_drop): Dropout(p=0.5, inplace=False)
              (projection): Linear(in_features=50, out_features=50, bias=True)
            )
            (2): Dropout(p=0.5, inplace=False)
          )
        )
        (1): ResidualAdd(
          (fn): Sequential(
            (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
            (1): FeedForwardBlock(
              (0): Linear(in_features=50, out_features=200, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.5, inplace=False)
              (3): Linear(in_features=200, out_features=50, bias=True)
            )
            (2): Dropout(p=0.5, inplace=False)
          )
        )
      )
      (1): Dis_TransformerEncoderBlock(
        (0): ResidualAdd(
          (fn): Sequential(
            (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
            (1): MultiHeadAttention(
              (keys): Linear(in_features=50, out_features=50, bias=True)
              (queries): Linear(in_features=50, out_features=50, bias=True)
              (values): Linear(in_features=50, out_features=50, bias=True)
              (att_drop): Dropout(p=0.5, inplace=False)
              (projection): Linear(in_features=50, out_features=50, bias=True)
            )
            (2): Dropout(p=0.5, inplace=False)
          )
        )
        (1): ResidualAdd(
          (fn): Sequential(
            (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
            (1): FeedForwardBlock(
              (0): Linear(in_features=50, out_features=200, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.5, inplace=False)
              (3): Linear(in_features=200, out_features=50, bias=True)
            )
            (2): Dropout(p=0.5, inplace=False)
          )
        )
      )
      (2): Dis_TransformerEncoderBlock(
        (0): ResidualAdd(
          (fn): Sequential(
            (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
            (1): MultiHeadAttention(
              (keys): Linear(in_features=50, out_features=50, bias=True)
              (queries): Linear(in_features=50, out_features=50, bias=True)
              (values): Linear(in_features=50, out_features=50, bias=True)
              (att_drop): Dropout(p=0.5, inplace=False)
              (projection): Linear(in_features=50, out_features=50, bias=True)
            )
            (2): Dropout(p=0.5, inplace=False)
          )
        )
        (1): ResidualAdd(
          (fn): Sequential(
            (0): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
            (1): FeedForwardBlock(
              (0): Linear(in_features=50, out_features=200, bias=True)
              (1): GELU(approximate='none')
              (2): Dropout(p=0.5, inplace=False)
              (3): Linear(in_features=200, out_features=50, bias=True)
            )
            (2): Dropout(p=0.5, inplace=False)
          )
        )
      )
    )
    (2): ClassificationHead(
      (clshead): Sequential(
        (0): Reduce('b n e -> b e', 'mean')
        (1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
        (2): Linear(in_features=50, out_features=1, bias=True)
      )
    )
  )
)
run
return single class data and labels, class is run
data shape is (15989, 3, 1, 30)
label shape is (15989,)
1000
Epochs between ckechpoint: 1




Saving checkpoint 1 in logs/Running_5000_D_30_2024_10_15_11_00_46/Model




[Epoch 0/5] [Batch 0/1000] [D loss: 1.149738] [G loss: 0.892987] [ema: 0.000000] 
[Epoch 0/5] [Batch 100/1000] [D loss: 0.441196] [G loss: 0.223204] [ema: 0.933033] 
[Epoch 0/5] [Batch 200/1000] [D loss: 0.327163] [G loss: 0.235886] [ema: 0.965936] 
[Epoch 0/5] [Batch 300/1000] [D loss: 0.261498] [G loss: 0.271330] [ema: 0.977160] 
[Epoch 0/5] [Batch 400/1000] [D loss: 0.263306] [G loss: 0.234186] [ema: 0.982821] 
[Epoch 0/5] [Batch 500/1000] [D loss: 0.352491] [G loss: 0.227959] [ema: 0.986233] 
[Epoch 0/5] [Batch 600/1000] [D loss: 0.330496] [G loss: 0.248136] [ema: 0.988514] 
[Epoch 0/5] [Batch 700/1000] [D loss: 0.413375] [G loss: 0.211258] [ema: 0.990147] 
[Epoch 0/5] [Batch 800/1000] [D loss: 0.390291] [G loss: 0.189832] [ema: 0.991373] 
[Epoch 0/5] [Batch 900/1000] [D loss: 0.413827] [G loss: 0.175051] [ema: 0.992328] 




Saving checkpoint 2 in logs/Running_5000_D_30_2024_10_15_11_00_46/Model




[Epoch 1/5] [Batch 0/1000] [D loss: 0.471682] [G loss: 0.150136] [ema: 0.993092] 
[Epoch 1/5] [Batch 100/1000] [D loss: 0.376782] [G loss: 0.217537] [ema: 0.993718] 
[Epoch 1/5] [Batch 200/1000] [D loss: 0.339552] [G loss: 0.208208] [ema: 0.994240] 
[Epoch 1/5] [Batch 300/1000] [D loss: 0.320828] [G loss: 0.204237] [ema: 0.994682] 
[Epoch 1/5] [Batch 400/1000] [D loss: 0.309346] [G loss: 0.245387] [ema: 0.995061] 
[Epoch 1/5] [Batch 500/1000] [D loss: 0.255361] [G loss: 0.245587] [ema: 0.995390] 
[Epoch 1/5] [Batch 600/1000] [D loss: 0.297740] [G loss: 0.231993] [ema: 0.995677] 
[Epoch 1/5] [Batch 700/1000] [D loss: 0.275728] [G loss: 0.203301] [ema: 0.995931] 
[Epoch 1/5] [Batch 800/1000] [D loss: 0.312048] [G loss: 0.245592] [ema: 0.996157] 
[Epoch 1/5] [Batch 900/1000] [D loss: 0.340574] [G loss: 0.222421] [ema: 0.996359] 




Saving checkpoint 3 in logs/Running_5000_D_30_2024_10_15_11_00_46/Model




[Epoch 2/5] [Batch 0/1000] [D loss: 0.343845] [G loss: 0.218661] [ema: 0.996540] 
[Epoch 2/5] [Batch 100/1000] [D loss: 0.418974] [G loss: 0.157173] [ema: 0.996705] 
[Epoch 2/5] [Batch 200/1000] [D loss: 0.371039] [G loss: 0.161937] [ema: 0.996854] 
[Epoch 2/5] [Batch 300/1000] [D loss: 0.429690] [G loss: 0.150924] [ema: 0.996991] 
[Epoch 2/5] [Batch 400/1000] [D loss: 0.467082] [G loss: 0.186220] [ema: 0.997116] 
[Epoch 2/5] [Batch 500/1000] [D loss: 0.496881] [G loss: 0.153345] [ema: 0.997231] 
[Epoch 2/5] [Batch 600/1000] [D loss: 0.456853] [G loss: 0.172267] [ema: 0.997338] 
[Epoch 2/5] [Batch 700/1000] [D loss: 0.440579] [G loss: 0.161728] [ema: 0.997436] 
[Epoch 2/5] [Batch 800/1000] [D loss: 0.384086] [G loss: 0.176643] [ema: 0.997528] 
[Epoch 2/5] [Batch 900/1000] [D loss: 0.396798] [G loss: 0.171387] [ema: 0.997613] 




Saving checkpoint 4 in logs/Running_5000_D_30_2024_10_15_11_00_46/Model




[Epoch 3/5] [Batch 0/1000] [D loss: 0.399710] [G loss: 0.210498] [ema: 0.997692] 
[Epoch 3/5] [Batch 100/1000] [D loss: 0.346181] [G loss: 0.147188] [ema: 0.997767] 
[Epoch 3/5] [Batch 200/1000] [D loss: 0.350289] [G loss: 0.209721] [ema: 0.997836] 
[Epoch 3/5] [Batch 300/1000] [D loss: 0.348511] [G loss: 0.209307] [ema: 0.997902] 
[Epoch 3/5] [Batch 400/1000] [D loss: 0.431392] [G loss: 0.174128] [ema: 0.997963] 
[Epoch 3/5] [Batch 500/1000] [D loss: 0.441951] [G loss: 0.213334] [ema: 0.998022] 
[Epoch 3/5] [Batch 600/1000] [D loss: 0.451850] [G loss: 0.202430] [ema: 0.998076] 
[Epoch 3/5] [Batch 700/1000] [D loss: 0.409903] [G loss: 0.177268] [ema: 0.998128] 
[Epoch 3/5] [Batch 800/1000] [D loss: 0.398839] [G loss: 0.192768] [ema: 0.998178] 
[Epoch 3/5] [Batch 900/1000] [D loss: 0.397115] [G loss: 0.182046] [ema: 0.998224] 




Saving checkpoint 5 in logs/Running_5000_D_30_2024_10_15_11_00_46/Model




[Epoch 4/5] [Batch 0/1000] [D loss: 0.379048] [G loss: 0.201615] [ema: 0.998269] 
[Epoch 4/5] [Batch 100/1000] [D loss: 0.365844] [G loss: 0.180549] [ema: 0.998311] 
[Epoch 4/5] [Batch 200/1000] [D loss: 0.352021] [G loss: 0.185548] [ema: 0.998351] 
[Epoch 4/5] [Batch 300/1000] [D loss: 0.437747] [G loss: 0.189116] [ema: 0.998389] 
[Epoch 4/5] [Batch 400/1000] [D loss: 0.451606] [G loss: 0.162684] [ema: 0.998426] 
[Epoch 4/5] [Batch 500/1000] [D loss: 0.491488] [G loss: 0.176462] [ema: 0.998461] 
[Epoch 4/5] [Batch 600/1000] [D loss: 0.456611] [G loss: 0.140760] [ema: 0.998494] 
[Epoch 4/5] [Batch 700/1000] [D loss: 0.412438] [G loss: 0.183743] [ema: 0.998526] 
[Epoch 4/5] [Batch 800/1000] [D loss: 0.438018] [G loss: 0.190022] [ema: 0.998557] 
[Epoch 4/5] [Batch 900/1000] [D loss: 0.316248] [G loss: 0.239713] [ema: 0.998586] 
