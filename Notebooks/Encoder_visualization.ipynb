{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import important packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from LoadRealRunningJumping import *\n",
    "from LoadSyntheticRunningJumping import *\n",
    "\n",
    "from GANModels import *\n",
    "\n",
    "from dataLoader import *\n",
    "\n",
    "import torch.fft as fft\n",
    "from torchsummary import summary\n",
    "\n",
    "from EvaluationFunctions import EncoderEvaluation\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and GAN generator and discriminator from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = '../pre-trained-models/daghar_split_dataset/seq_len_30/3axis/'\n",
    "data_path = '../DAGHAR_split_25_10/train/data/KuHar_DAGHAR_Multiclass.csv'\n",
    "label_path = '../DAGHAR_split_25_10/train/label/KuHar_Label_Multiclass.csv'\n",
    "\n",
    "original_set = daghar_load_dataset_with_label(class_name= \"kuhar\",\n",
    "                                              seq_len=30,\n",
    "                                              data_path=data_path,\n",
    "                                              label_path=label_path,\n",
    "                                              channels=3)\n",
    "\n",
    "gen_model = Generator(seq_len=30, channels=3).cuda()\n",
    "running_model = Discriminator(seq_len=30, in_channels=3)\n",
    "running_ckp = torch.load(models_path + 'KuHar_DAGHAR_Multiclass_50000_D_30_2024_10_25_02_42_43/Model/checkpoint')\n",
    "running_model.load_state_dict(running_ckp['dis_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(gen_model, (1, 3, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator(seq_len=30, in_channels=3).cuda()\n",
    "summary(model, (3, 1, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set discriminator to encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_remove = list(running_ckp['dis_state_dict'].keys())[-4:]  # Obtém as últimas 4 chaves\n",
    "\n",
    "print(f\"original keys: {running_ckp['dis_state_dict'].keys()}\")\n",
    "# Remove as chaves do dicionário original\n",
    "for key in keys_to_remove:\n",
    "    del running_ckp['dis_state_dict'][key]\n",
    "\n",
    "# Verificando o resultado\n",
    "print(f\"ajusted keys: {running_ckp['dis_state_dict'].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Sequential):\n",
    "    def __init__(self, \n",
    "                 in_channels=3,\n",
    "                 patch_size=15,\n",
    "                 emb_size=50, \n",
    "                 seq_len = 150,\n",
    "                 depth=3, \n",
    "                 n_classes=1, \n",
    "                 **kwargs):\n",
    "        super().__init__(\n",
    "            PatchEmbedding_Linear(in_channels, patch_size, emb_size, seq_len),\n",
    "            Dis_TransformerEncoder(depth, emb_size=emb_size, drop_p=0.5, forward_drop_p=0.5, **kwargs)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(in_channels=3, seq_len=30).cuda()\n",
    "summary(encoder, (3, 1, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(running_ckp['dis_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.from_numpy(original_set[:][0]).float().to('cuda')\n",
    "labels = torch.from_numpy(original_set[:][1])\n",
    "print(samples.shape)\n",
    "forward = encoder(samples)\n",
    "print(forward.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSNE_visualization(data, labels, title='t-SNE plot', show=True, save_path=''):\n",
    "    '''\n",
    "\n",
    "    Espera-se que os dados originais estejam na forma (batch, channels, timeframe), por exemplo, (2784, 3, 50)\n",
    "    \n",
    "    '''\n",
    "    colors = [\n",
    "        \"#FF5733\",  # Vermelho\n",
    "        \"#337BFF\",  # Azul\n",
    "        \"#33FF57\",  # Verde\n",
    "        \"#FFD133\",  # Amarelo\n",
    "        \"#9B33FF\",  # Roxo\n",
    "        \"#33FFF6\"   # Ciano\n",
    "        ]\n",
    "    actions = ['sit', 'stand', 'walk', 'upstairs', 'downstairs', 'run']\n",
    "\n",
    "    # Garantir que os dados são numpy array e embaralhar com labels\n",
    "    data = np.asarray(data)\n",
    "    labels = np.asarray(labels)\n",
    "    l = len(data)\n",
    "    idx = np.random.permutation(l)\n",
    "    data, labels = data[idx], labels[idx]\n",
    "\n",
    "        # Pré-processamento: média ao longo da dimensão dos canais (dim=1)\n",
    "        # Para cada batch, reduzimos para uma representação média de forma (2784, 50)\n",
    "    prep = np.mean(data, axis=1)\n",
    "    print(\"Shape após a média por canal:\", prep.shape)\n",
    "\n",
    "    # Análise TSNE\n",
    "    tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(prep)\n",
    "    print(\"Shape do resultado TSNE:\", tsne_results.shape)\n",
    "\n",
    "    # Plotagem\n",
    "    if not show:\n",
    "        return tsne_results\n",
    "\n",
    "    f, ax = plt.subplots(1, figsize=(12,6))\n",
    "\n",
    "    scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], \n",
    "                          c=[colors[label] for label in labels], alpha=0.6)\n",
    "        # Criar uma legenda customizada para as classes\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors[i], markersize=10) for i in range(len(actions))]\n",
    "    ax.legend(handles, actions, title=\"Actions\")\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('x-tsne')\n",
    "    ax.set_ylabel('y-tsne')\n",
    "    if save_path:\n",
    "        f.savefig(save_path + title + '.png')\n",
    "\n",
    "    return tsne_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_visualization(forward.cpu().detach().numpy(),labels, title = 'tsne: kuhar', show=True,\n",
    "                   save_path='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dis_TransformerEncoderBlock(nn.Sequential):\n",
    "    def __init__(self,\n",
    "                 emb_size=100,\n",
    "                 num_heads=5,\n",
    "                 drop_p=0.,\n",
    "                 forward_expansion=4,\n",
    "                 forward_drop_p=0.):\n",
    "        super().__init__(\n",
    "            ResidualAdd(nn.Sequential(nn.LayerNorm(emb_size),\n",
    "                                      MultiHeadAttention(emb_size, num_heads, drop_p),\n",
    "                                      nn.Dropout(drop_p))),\n",
    "\n",
    "            ResidualAdd(nn.Sequential(nn.LayerNorm(emb_size),\n",
    "                                      FeedForwardBlock(emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
    "                                      nn.Dropout(drop_p)))\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "class Dis_TransformerEncoder(nn.Sequential):\n",
    "    def __init__(self, depth=8, **kwargs):\n",
    "        super().__init__(*[Dis_TransformerEncoderBlock(**kwargs) for _ in range(depth)])\n",
    "\n",
    "class PatchEmbedding_Linear(nn.Module):\n",
    "    #what are the proper parameters set here?\n",
    "    def __init__(self, in_channels = 21, patch_size = 16, emb_size = 100, seq_len = 1024):\n",
    "        # self.patch_size = patch_size\n",
    "        super().__init__()\n",
    "        #change the conv2d parameters here\n",
    "        self.rearrange = Rearrange('b c (h s1) (w s2) -> b (h w) (s1 s2 c)',s1 = 1, s2 = patch_size)\n",
    "        self.linear = nn.Linear(patch_size*in_channels, emb_size)\n",
    "        self.projection = nn.Sequential(\n",
    "            Rearrange('b c (h s1) (w s2) -> b (h w) (s1 s2 c)',s1 = 1, s2 = patch_size),\n",
    "            nn.Linear(patch_size*in_channels, emb_size)\n",
    "        )\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))\n",
    "        self.positions = nn.Parameter(torch.randn((seq_len // patch_size) + 1, emb_size))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        print(f'forward in shape: {x.shape}')\n",
    "        b, _, _, _ = x.shape\n",
    "        x = self.rearrange(x)\n",
    "        print(f'After REARRANGE shape: {x.shape}')\n",
    "        x = self.linear(x)\n",
    "        print(f'after Linear layer shape: {x.shape}')\n",
    "        print(f'\\n cls_token initial shape: {self.cls_token.shape}')\n",
    "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
    "        #cls_tokens = self.cls_token.repeat(b, 1, 1) #Personal repeat from pytorch to transfer from einops\n",
    "        #prepend the cls token to the input\n",
    "        print(f' cls_tokens shape: {cls_tokens.shape}')\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "        # position\n",
    "        x += self.positions\n",
    "        return x        \n",
    "        \n",
    "class Encoder(nn.Sequential):\n",
    "    def __init__(self, \n",
    "                 in_channels=3,\n",
    "                 patch_size=15,\n",
    "                 emb_size=50, \n",
    "                 seq_len = 150,\n",
    "                 depth=3,  \n",
    "                 **kwargs):\n",
    "        super().__init__(\n",
    "            PatchEmbedding_Linear(in_channels, patch_size, emb_size, seq_len),\n",
    "            Dis_TransformerEncoder(depth, emb_size=emb_size, drop_p=0.5, forward_drop_p=0.5, **kwargs),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "test_encoder = Encoder(in_channels=3, patch_size=15, emb_size=50, seq_len=30, depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data original shape in: (2, 3, 1, 30)\n",
      "forward in shape: torch.Size([2, 3, 1, 30])\n",
      "After REARRANGE shape: torch.Size([2, 2, 45])\n",
      "after Linear layer shape: torch.Size([2, 2, 50])\n",
      "\n",
      " cls_token initial shape: torch.Size([1, 1, 50])\n",
      " cls_tokens shape: torch.Size([2, 1, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0571e+00, -5.8690e-01, -7.2749e-01,  6.6194e-02,  1.8601e-01,\n",
       "           6.1001e-01, -1.7726e+00, -4.5558e+00, -4.3648e-01, -2.1551e+00,\n",
       "          -1.5407e+00, -7.6107e-01, -9.7441e-01,  1.7416e+00, -9.8297e-01,\n",
       "           3.5182e-01, -1.7474e-01, -9.9338e-01, -5.4105e-01, -1.8193e+00,\n",
       "           5.0723e-03,  2.4914e+00,  1.7360e-01, -3.5390e-01, -9.0261e-01,\n",
       "          -6.7927e-01,  2.3131e+00, -1.0954e+00,  2.6914e+00,  9.8820e-01,\n",
       "           2.7738e-01, -5.4304e-01,  5.8782e-01,  4.9031e-01, -1.6927e+00,\n",
       "          -2.2878e+00,  4.8508e+00, -1.8930e+00,  3.9537e-01, -9.9192e-01,\n",
       "          -5.8826e-01, -1.0439e+00,  5.4816e-01, -1.0574e+00, -1.1124e-01,\n",
       "          -1.0655e+00,  1.9237e-02,  3.0961e+00,  8.4294e-01,  3.8517e-01],\n",
       "         [ 2.1679e-01, -4.0678e-01, -2.6577e-01,  6.6641e-01, -1.5241e+00,\n",
       "          -5.5468e-01, -1.0177e+00, -2.4124e-01, -5.1565e-01, -4.2608e+00,\n",
       "           1.1483e+00,  7.5558e-01,  1.2840e+00, -1.0479e+00,  1.0254e+00,\n",
       "          -7.2666e-01,  2.1565e-01, -1.2774e+00,  1.5996e+00,  7.8373e-01,\n",
       "          -4.9123e-01, -1.3842e+00, -1.0820e+00,  1.5620e+00, -1.8947e-01,\n",
       "          -2.7598e-01, -1.1527e+00, -2.6657e+00,  9.2173e-01, -1.1540e+00,\n",
       "           1.3317e+00, -3.9156e-01,  5.6390e-02, -1.4609e+00,  5.4354e-01,\n",
       "          -5.5301e-01, -2.5538e+00,  1.7134e+00,  7.1578e-01, -1.2288e+00,\n",
       "          -7.2606e-01, -7.4684e-01, -5.5308e-01,  2.4267e+00, -1.1074e+00,\n",
       "          -1.0817e+00, -1.2942e+00,  3.8274e-01, -1.7659e+00, -7.4565e-01],\n",
       "         [-1.3330e+00, -3.8699e+00, -1.1539e+00,  5.6960e-02, -1.5336e+00,\n",
       "           2.2734e-03, -1.8406e+00, -1.3599e+00, -6.2998e-01, -5.0936e-01,\n",
       "          -2.3680e+00, -9.2389e-01, -4.1544e-01, -6.6696e-01,  4.0623e-01,\n",
       "          -5.7366e-01, -1.8063e+00, -1.4004e+00,  6.2413e-01, -2.6884e+00,\n",
       "          -1.3184e+00,  8.5174e-01, -1.4766e+00,  5.2690e-01, -1.8628e+00,\n",
       "          -7.0762e-01,  1.7495e+00, -6.5535e-01, -8.1619e-01,  3.6472e-01,\n",
       "          -2.0205e-03,  1.6191e-01, -1.2612e+00, -4.4935e-01, -5.0159e-01,\n",
       "           9.5735e-01, -1.4476e-01, -1.1154e+00, -2.0758e-01,  1.6106e+00,\n",
       "          -6.3661e-01,  6.0215e-02,  1.2002e+00, -3.1533e+00, -1.1687e-01,\n",
       "          -1.9060e+00,  1.2144e+00,  1.7425e+00,  4.0470e-01,  1.2326e+00]],\n",
       "\n",
       "        [[ 4.8774e-01,  9.1415e-01, -7.7720e-01,  3.8229e-01, -9.4595e-01,\n",
       "           5.7682e-01, -9.6840e-01, -2.8190e+00,  4.2245e-01, -3.8380e-01,\n",
       "          -2.1654e+00, -3.3479e+00, -1.4292e+00,  1.1939e+00,  8.5324e-01,\n",
       "          -3.8573e-01, -1.8541e+00, -3.0571e+00,  1.2422e+00, -7.6767e-01,\n",
       "           7.0805e-01,  3.6116e+00, -1.4062e+00, -2.0556e-01, -2.1236e+00,\n",
       "           3.0307e-02,  2.9405e+00, -3.0535e-01,  3.4438e+00,  3.3625e-02,\n",
       "           5.8852e-02, -1.1056e+00,  3.7355e-01,  3.8343e-01, -3.7307e+00,\n",
       "          -1.7048e+00,  4.5868e+00, -2.3940e+00,  1.7665e+00, -1.2367e+00,\n",
       "          -2.6594e-01, -7.0060e-01,  1.3739e+00, -1.3756e+00,  1.0122e+00,\n",
       "           1.0461e-01, -8.0155e-01,  1.2966e+00,  1.2640e+00,  2.0410e-02],\n",
       "         [ 7.0135e-01,  1.5493e+00, -8.7878e-02,  1.5364e+00, -4.4218e-01,\n",
       "          -1.0445e+00, -1.0792e+00,  1.1405e+00,  3.5745e-01, -1.1679e+00,\n",
       "          -6.5548e-01, -4.6895e-02,  5.2046e-01,  3.5073e-01, -9.2774e-01,\n",
       "          -1.2651e+00, -1.8393e+00,  6.8321e-02,  1.9878e+00,  8.2225e-01,\n",
       "          -6.2391e-01, -3.4660e+00, -9.2772e-01,  1.5438e+00,  1.1777e+00,\n",
       "          -1.4819e+00, -2.9991e+00, -1.9253e+00,  7.2809e-01, -2.5394e+00,\n",
       "          -3.3616e-01, -3.9937e-02, -7.9397e-01, -3.3058e-01,  7.4981e-01,\n",
       "          -1.3335e+00,  3.0487e-01,  1.9683e+00,  8.5004e-01,  3.7447e-01,\n",
       "          -6.5936e-01, -3.6604e-01,  2.5495e-01,  2.7987e+00, -6.0047e-01,\n",
       "           1.9571e-02, -1.9639e+00,  5.2993e-01, -3.4172e-01,  1.4741e-01],\n",
       "         [-6.7081e-01, -8.3866e-01, -1.7417e+00,  1.0810e+00, -2.6821e+00,\n",
       "           9.8880e-01, -6.6501e-01, -1.3821e+00,  1.8754e+00, -1.1638e+00,\n",
       "          -1.2295e+00, -2.0970e+00, -1.3810e+00, -2.0126e+00, -2.2682e-01,\n",
       "          -3.2839e-01, -2.6408e+00, -1.7964e+00,  1.1681e-01, -1.5276e+00,\n",
       "          -2.9064e+00, -4.9113e-01,  2.9528e-01,  8.2934e-01, -4.2554e+00,\n",
       "          -2.0620e+00,  1.0426e+00,  5.2409e-01,  4.4589e-01, -5.2381e-01,\n",
       "           7.2030e-01, -4.9079e-01, -1.7972e+00, -1.8050e+00,  1.3568e+00,\n",
       "           1.4162e-01,  1.9176e+00, -1.9019e+00, -7.2932e-02,  5.9988e-01,\n",
       "          -1.8155e+00, -1.7848e+00,  4.5067e-01, -1.8465e+00, -1.9354e+00,\n",
       "           7.3066e-01, -7.8617e-01,  2.1978e+00, -3.6704e-02, -2.5928e+00]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "print(f'data original shape in: {original_set[:2][0].shape}')\n",
    "loggits = test_encoder(torch.from_numpy(original_set[:2][0]).float())\n",
    "loggits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True]]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol == loggits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Função para converter até o primeiro número\n",
    "def convert_string(s):\n",
    "    # Encontrar a parte da string antes do primeiro número\n",
    "    match = re.match(r'([^\\d]+)(\\d+)', s)\n",
    "    if match:\n",
    "        # Extrair a parte antes e o número\n",
    "        prefix = match.group(1).lower()  # Parte antes do número, convertida para minúsculas\n",
    "        number = match.group(2)          # Primeiro número encontrado\n",
    "        return f\"{prefix}{number}\"       # Retorna no formato desejado\n",
    "    return s  # Retorna a string original se não houver números"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3axis seq_len 30 split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = '../pre-trained-models/daghar_split_dataset/seq_len_30/3axis/'\n",
    "data_path = '../DAGHAR_split_25_10/train/'\n",
    "directorys = os.listdir(models_path)\n",
    "\n",
    "first_parts = [item.split(\"Multiclass\")[0] + \"Multiclass\" for item in directorys]\n",
    "class_names = [item.split(\"_DAGHAR\")[0] for item in directorys]\n",
    "label_paths = [s.replace('DAGHAR', 'Label') for s in first_parts] \n",
    "directorys, class_names, first_parts, label_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting Encoder Evaluation')\n",
    "print('---------------------------------------------------------------------------------------')\n",
    "for i in range(len(class_names)):\n",
    "    Eval = EncoderEvaluation(\n",
    "                 models_path = models_path + directorys[i] + '/Model/checkpoint',\n",
    "                 class_name = class_names[i],\n",
    "                 seq_len = 30,\n",
    "                 channels = 3,\n",
    "                 save_path = '../Notebooks/Encoder_View/split_dataset/seq_len_30/3axis/' ,\n",
    "                 data_path = data_path + 'data/' + first_parts[i] + '.csv',\n",
    "                 label_path = data_path + 'label/' + label_paths[i] + '.csv',\n",
    "                 show=False)\n",
    "    print('---------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6axis seq_len 30 split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = '../pre-trained-models/daghar_split_dataset/seq_len_30/6axis/'\n",
    "data_path = '../DAGHAR_split_25_10/train/'\n",
    "directorys = os.listdir(models_path)\n",
    "\n",
    "first_parts = [item.split(\"Multiclass\")[0] + \"Multiclass\" for item in directorys]\n",
    "class_names = [item.split(\"_DAGHAR\")[0] for item in directorys]\n",
    "label_paths = [s.replace('DAGHAR', 'Label') for s in first_parts] \n",
    "directorys, class_names, first_parts, label_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting Encoder Evaluation')\n",
    "print('---------------------------------------------------------------------------------------')\n",
    "for i in range(len(class_names)):\n",
    "    Eval = EncoderEvaluation(\n",
    "                 models_path = models_path + directorys[i] + '/Model/checkpoint',\n",
    "                 class_name = class_names[i],\n",
    "                 seq_len = 30,\n",
    "                 channels = 6,\n",
    "                 save_path = '../Notebooks/Encoder_View/split_dataset/seq_len_30/6axis/' ,\n",
    "                 data_path = data_path + 'data/' + first_parts[i] + '.csv',\n",
    "                 label_path = data_path + 'label/' + label_paths[i] + '.csv',\n",
    "                 show=False)\n",
    "    print('---------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3axis seq_len 60 split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = '../pre-trained-models/daghar_split_dataset/seq_len_60/3axis/'\n",
    "data_path = '../DAGHAR_split_25_10/train/'\n",
    "directorys = os.listdir(models_path)\n",
    "\n",
    "first_parts = [item.split(\"Multiclass\")[0] + \"Multiclass\" for item in directorys]\n",
    "class_names = [item.split(\"_DAGHAR\")[0] for item in directorys]\n",
    "label_paths = [s.replace('DAGHAR', 'Label') for s in first_parts] \n",
    "directorys, class_names, first_parts, label_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do resultado TSNE: (8748, 2)\n",
      "---------------------------------------------------------------------------------------\n",
      "class name : UCI\n",
      "Data path is located in: ../DAGHAR_split_25_10/train/data/UCI_DAGHAR_Multiclass.csv\n",
      "Label path is located in: ../DAGHAR_split_25_10/train/label/UCI_Label_Multiclass.csv\n",
      "Models path is located in: ../pre-trained-models/daghar_split_dataset/seq_len_60/3axis/UCI_DAGHAR_Multiclass_50000_D_60_2024_10_25_15_53_51/Model/checkpoint\n",
      "dataset: Daghar\n",
      " \n",
      " Starting Encoder Evaluation\n",
      "Original Set:\n",
      "return single class data and labels, class is UCI\n",
      "data shape is (2420, 3, 1, 60)\n",
      "label shape is (2420,)\n",
      "1: torch.Size([2420, 3, 1, 60])\n",
      "2: torch.Size([2420, 4, 50])\n",
      "forward shape: (2420, 5, 50)\n",
      "Shape após a média por canal: (2420, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/container-workspace/tts-gan/Notebooks/EvaluationFunctions.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(self.models_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do resultado TSNE: (2420, 2)\n",
      "---------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Starting Encoder Evaluation')\n",
    "print('---------------------------------------------------------------------------------------')\n",
    "for i in range(len(class_names)):\n",
    "    Eval = EncoderEvaluation(\n",
    "                 models_path = models_path + directorys[i] + '/Model/checkpoint',\n",
    "                 class_name = class_names[i],\n",
    "                 seq_len = 60,\n",
    "                 channels = 3,\n",
    "                 save_path = '../Notebooks/Encoder_View/split_dataset/seq_len_60/3axis/' ,\n",
    "                 data_path = data_path + 'data/' + first_parts[i] + '.csv',\n",
    "                 label_path = data_path + 'label/' + label_paths[i] + '.csv',\n",
    "                 show=False)\n",
    "    print('---------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6axis seq_len 60 split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['KuHar_DAGHAR_Multiclass_50000_D_60_2024_10_30_03_01_46',\n",
       "  'MotionSense_DAGHAR_Multiclass_50000_D_60_2024_10_30_00_07_49',\n",
       "  'RealWorld_thigh_DAGHAR_Multiclass_50000_D_60_2024_10_30_00_43_14',\n",
       "  'UCI_DAGHAR_Multiclass_50000_D_60_2024_10_30_01_50_17',\n",
       "  'WISDM_DAGHAR_Multiclass_50000_D_60_2024_10_30_01_16_54',\n",
       "  'RealWorld_waist_DAGHAR_Multiclass_50000_D_60_2024_10_30_02_28_08'],\n",
       " ['KuHar',\n",
       "  'MotionSense',\n",
       "  'RealWorld_thigh',\n",
       "  'UCI',\n",
       "  'WISDM',\n",
       "  'RealWorld_waist'],\n",
       " ['KuHar_DAGHAR_Multiclass',\n",
       "  'MotionSense_DAGHAR_Multiclass',\n",
       "  'RealWorld_thigh_DAGHAR_Multiclass',\n",
       "  'UCI_DAGHAR_Multiclass',\n",
       "  'WISDM_DAGHAR_Multiclass',\n",
       "  'RealWorld_waist_DAGHAR_Multiclass'],\n",
       " ['KuHar_Label_Multiclass',\n",
       "  'MotionSense_Label_Multiclass',\n",
       "  'RealWorld_thigh_Label_Multiclass',\n",
       "  'UCI_Label_Multiclass',\n",
       "  'WISDM_Label_Multiclass',\n",
       "  'RealWorld_waist_Label_Multiclass'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_path = '../pre-trained-models/daghar_split_dataset/seq_len_60/6axis/'\n",
    "data_path = '../DAGHAR_split_25_10/train/'\n",
    "directorys = os.listdir(models_path)\n",
    "\n",
    "first_parts = [item.split(\"Multiclass\")[0] + \"Multiclass\" for item in directorys]\n",
    "class_names = [item.split(\"_DAGHAR\")[0] for item in directorys]\n",
    "label_paths = [s.replace('DAGHAR', 'Label') for s in first_parts] \n",
    "directorys, class_names, first_parts, label_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Encoder Evaluation\n",
      "---------------------------------------------------------------------------------------\n",
      "class name : KuHar\n",
      "Data path is located in: ../DAGHAR_split_25_10/train/data/KuHar_DAGHAR_Multiclass.csv\n",
      "Label path is located in: ../DAGHAR_split_25_10/train/label/KuHar_Label_Multiclass.csv\n",
      "Models path is located in: ../pre-trained-models/daghar_split_dataset/seq_len_60/6axis/KuHar_DAGHAR_Multiclass_50000_D_60_2024_10_30_03_01_46/Model/checkpoint\n",
      "dataset: Daghar\n",
      " \n",
      " Starting Encoder Evaluation\n",
      "Original Set:\n",
      "return single class data and labels, class is KuHar\n",
      "data shape is (1392, 6, 1, 60)\n",
      "label shape is (1392,)\n",
      "1: torch.Size([1392, 6, 1, 60])\n",
      "2: torch.Size([1392, 4, 50])\n",
      "forward shape: (1392, 5, 50)\n",
      "Shape após a média por canal: (1392, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/container-workspace/tts-gan/Notebooks/EvaluationFunctions.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(self.models_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do resultado TSNE: (1392, 2)\n",
      "---------------------------------------------------------------------------------------\n",
      "class name : MotionSense\n",
      "Data path is located in: ../DAGHAR_split_25_10/train/data/MotionSense_DAGHAR_Multiclass.csv\n",
      "Label path is located in: ../DAGHAR_split_25_10/train/label/MotionSense_Label_Multiclass.csv\n",
      "Models path is located in: ../pre-trained-models/daghar_split_dataset/seq_len_60/6axis/MotionSense_DAGHAR_Multiclass_50000_D_60_2024_10_30_00_07_49/Model/checkpoint\n",
      "dataset: Daghar\n",
      " \n",
      " Starting Encoder Evaluation\n",
      "Original Set:\n",
      "return single class data and labels, class is MotionSense\n",
      "data shape is (3558, 6, 1, 60)\n",
      "label shape is (3558,)\n",
      "1: torch.Size([3558, 6, 1, 60])\n",
      "2: torch.Size([3558, 4, 50])\n",
      "forward shape: (3558, 5, 50)\n",
      "Shape após a média por canal: (3558, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/container-workspace/tts-gan/Notebooks/EvaluationFunctions.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(self.models_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do resultado TSNE: (3558, 2)\n",
      "---------------------------------------------------------------------------------------\n",
      "class name : RealWorld_thigh\n",
      "Data path is located in: ../DAGHAR_split_25_10/train/data/RealWorld_thigh_DAGHAR_Multiclass.csv\n",
      "Label path is located in: ../DAGHAR_split_25_10/train/label/RealWorld_thigh_Label_Multiclass.csv\n",
      "Models path is located in: ../pre-trained-models/daghar_split_dataset/seq_len_60/6axis/RealWorld_thigh_DAGHAR_Multiclass_50000_D_60_2024_10_30_00_43_14/Model/checkpoint\n",
      "dataset: Daghar\n",
      " \n",
      " Starting Encoder Evaluation\n",
      "Original Set:\n",
      "return single class data and labels, class is RealWorld_thigh\n",
      "data shape is (10338, 6, 1, 60)\n",
      "label shape is (10338,)\n",
      "1: torch.Size([10338, 6, 1, 60])\n",
      "2: torch.Size([10338, 4, 50])\n",
      "forward shape: (10338, 5, 50)\n",
      "Shape após a média por canal: (10338, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/container-workspace/tts-gan/Notebooks/EvaluationFunctions.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(self.models_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do resultado TSNE: (10338, 2)\n",
      "---------------------------------------------------------------------------------------\n",
      "class name : UCI\n",
      "Data path is located in: ../DAGHAR_split_25_10/train/data/UCI_DAGHAR_Multiclass.csv\n",
      "Label path is located in: ../DAGHAR_split_25_10/train/label/UCI_Label_Multiclass.csv\n",
      "Models path is located in: ../pre-trained-models/daghar_split_dataset/seq_len_60/6axis/UCI_DAGHAR_Multiclass_50000_D_60_2024_10_30_01_50_17/Model/checkpoint\n",
      "dataset: Daghar\n",
      " \n",
      " Starting Encoder Evaluation\n",
      "Original Set:\n",
      "return single class data and labels, class is UCI\n",
      "data shape is (2420, 6, 1, 60)\n",
      "label shape is (2420,)\n",
      "1: torch.Size([2420, 6, 1, 60])\n",
      "2: torch.Size([2420, 4, 50])\n",
      "forward shape: (2420, 5, 50)\n",
      "Shape após a média por canal: (2420, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/container-workspace/tts-gan/Notebooks/EvaluationFunctions.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(self.models_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do resultado TSNE: (2420, 2)\n",
      "---------------------------------------------------------------------------------------\n",
      "class name : WISDM\n",
      "Data path is located in: ../DAGHAR_split_25_10/train/data/WISDM_DAGHAR_Multiclass.csv\n",
      "Label path is located in: ../DAGHAR_split_25_10/train/label/WISDM_Label_Multiclass.csv\n",
      "Models path is located in: ../pre-trained-models/daghar_split_dataset/seq_len_60/6axis/WISDM_DAGHAR_Multiclass_50000_D_60_2024_10_30_01_16_54/Model/checkpoint\n",
      "dataset: Daghar\n",
      " \n",
      " Starting Encoder Evaluation\n",
      "Original Set:\n",
      "return single class data and labels, class is WISDM\n",
      "data shape is (8748, 6, 1, 60)\n",
      "label shape is (8748,)\n",
      "1: torch.Size([8748, 6, 1, 60])\n",
      "2: torch.Size([8748, 4, 50])\n",
      "forward shape: (8748, 5, 50)\n",
      "Shape após a média por canal: (8748, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/container-workspace/tts-gan/Notebooks/EvaluationFunctions.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(self.models_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do resultado TSNE: (8748, 2)\n",
      "---------------------------------------------------------------------------------------\n",
      "class name : RealWorld_waist\n",
      "Data path is located in: ../DAGHAR_split_25_10/train/data/RealWorld_waist_DAGHAR_Multiclass.csv\n",
      "Label path is located in: ../DAGHAR_split_25_10/train/label/RealWorld_waist_Label_Multiclass.csv\n",
      "Models path is located in: ../pre-trained-models/daghar_split_dataset/seq_len_60/6axis/RealWorld_waist_DAGHAR_Multiclass_50000_D_60_2024_10_30_02_28_08/Model/checkpoint\n",
      "dataset: Daghar\n",
      " \n",
      " Starting Encoder Evaluation\n",
      "Original Set:\n",
      "return single class data and labels, class is RealWorld_waist\n",
      "data shape is (10332, 6, 1, 60)\n",
      "label shape is (10332,)\n",
      "1: torch.Size([10332, 6, 1, 60])\n",
      "2: torch.Size([10332, 4, 50])\n",
      "forward shape: (10332, 5, 50)\n",
      "Shape após a média por canal: (10332, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/container-workspace/tts-gan/Notebooks/EvaluationFunctions.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckp = torch.load(self.models_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do resultado TSNE: (10332, 2)\n",
      "---------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Starting Encoder Evaluation')\n",
    "print('---------------------------------------------------------------------------------------')\n",
    "for i in range(len(class_names)):\n",
    "    Eval = EncoderEvaluation(\n",
    "                 models_path = models_path + directorys[i] + '/Model/checkpoint',\n",
    "                 class_name = class_names[i],\n",
    "                 seq_len = 60,\n",
    "                 channels = 6,\n",
    "                 save_path = '../Notebooks/Encoder_View/split_dataset/seq_len_60/6axis/' ,\n",
    "                 data_path = data_path + 'data/' + first_parts[i] + '.csv',\n",
    "                 label_path = data_path + 'label/' + label_paths[i] + '.csv',\n",
    "                 show=False)\n",
    "    print('---------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
